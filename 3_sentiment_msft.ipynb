{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24da7048",
   "metadata": {},
   "source": [
    "# Computing Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b078a2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 10:25:27.716240: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, TimeDistributed, Dropout\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from plot_model import plot_model\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from transformers import TFBertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1cc834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 10:25:38.035835: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d413f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(sentences, tokenizer, seq_len = 256): \n",
    "    '''\n",
    "    This function takes all input sentences and creates a batch of tokens.\n",
    "    The batch size is same as the number of inputs.\n",
    "    We truncate all inpnut_ids of length greater than seq_len. We will not split large texts\n",
    "    \n",
    "    We used seq_len = 256 while training the FSAB classification model\n",
    "    '''\n",
    "    \n",
    "    batch_size = len(sentences)\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        \n",
    "        tokens = tokenizer.tokenize(sentence.numpy().decode()) # reading the text\n",
    "        tokens = ['[CLS]']+tokens+['[SEP]'] # prepending and appending with classification and seperator tokens\n",
    "        \n",
    "        temp_input_ids = tokenizer.convert_tokens_to_ids(tokens) # create temporary list of input_ids\n",
    "        \n",
    "        while len(temp_input_ids) > seq_len: # Truncation\n",
    "            sep = input_ids.pop()\n",
    "            input_ids[-1] = sep\n",
    "        \n",
    "        temp_attention_mask = [1]*len(temp_input_ids) # create temporary attention mask\n",
    "        \n",
    "        while len(temp_input_ids) < seq_len: # Padding\n",
    "            temp_input_ids.append(0)\n",
    "            temp_attention_mask.append(0)\n",
    "        \n",
    "        input_ids = input_ids + temp_input_ids\n",
    "        attention_mask = attention_mask + temp_attention_mask\n",
    "    \n",
    "    input_ids = tf.reshape(tf.convert_to_tensor(input_ids),[batch_size,seq_len])\n",
    "    attention_mask = tf.reshape(tf.convert_to_tensor(attention_mask),[batch_size,seq_len])\n",
    "    \n",
    "    return input_ids, attention_mask # We are passing 2 separate tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e82d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('MSFT_news_2020_onwards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a5e237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df=news_df.replace(np.nan,'',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be320e21",
   "metadata": {},
   "source": [
    "We will use only the first 5 headlines as upon inspection, it appears that the later headlines are often not relevant for microsoft. Keeping irrelevant headlines may negatively impact the performance of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "67692c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to tensorflow tensors\n",
    "\n",
    "h1 = tf.constant(news_df['headline1'])\n",
    "h2 = tf.constant(news_df['headline2'])\n",
    "h3 = tf.constant(news_df['headline3'])\n",
    "h4 = tf.constant(news_df['headline4'])\n",
    "h5 = tf.constant(news_df['headline5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df2ba2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to BERT inputs\n",
    "\n",
    "h1_bert = custom_tokenizer(h1,tokenizer)\n",
    "h2_bert = custom_tokenizer(h2,tokenizer)\n",
    "h3_bert = custom_tokenizer(h3,tokenizer)\n",
    "h4_bert = custom_tokenizer(h4,tokenizer)\n",
    "h5_bert = custom_tokenizer(h5,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b0491ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset from tensor slices to boost performance by enabling parallelization.\n",
    "\n",
    "h1_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids':h1_bert[0],'attention_mask':h1_bert[1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22dc521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_dataset = h1_dataset.cache().batch(64).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe54b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c585990",
   "metadata": {},
   "source": [
    "# Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7b59921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "\n",
    "seq_len = 256\n",
    "\n",
    "input_ids = Input(shape=(seq_len,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = Input(shape=(seq_len,), dtype=tf.int32, name='attention_mask')\n",
    "\n",
    "pooled_output = bert_model(input_ids, attention_mask=attention_mask)\n",
    "dropout_layer = Dropout(0.2)(pooled_output[1])\n",
    "\n",
    "hidden_layer = Dense(128,activation='tanh',name = 'hidden_layer')(dropout_layer)\n",
    "dropout_layer_2 = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "classification_layer=Dense(3,activation=tf.nn.softmax, name = 'output_layer')(dropout_layer_2)\n",
    "\n",
    "FSAB_model = tf.keras.Model(inputs=[input_ids,attention_mask], outputs=classification_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b057864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fd8ead25750>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading weights\n",
    "\n",
    "FSAB_model.load_weights('/Users/pushkal/Documents/work/Industry/preparation/Programming/Projects/Sentiment_analysis_BERT/notebooks/saved_weights/FSAB_05_25_2023_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22003133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 768)          0           ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      " hidden_layer (Dense)           (None, 128)          98432       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 128)          0           ['hidden_layer[0][0]']           \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 3)            387         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,581,059\n",
      "Trainable params: 0\n",
      "Non-trainable params: 109,581,059\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FSAB_model.trainable = False\n",
    "FSAB_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d9c61e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 364s 18s/step\n"
     ]
    }
   ],
   "source": [
    "sentiment1 = FSAB_model.predict(h1_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57c271e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4670238e-04, 9.9414921e-01, 5.5041686e-03],\n",
       "       [6.9052307e-04, 9.4470626e-01, 5.4603208e-02],\n",
       "       [9.5169619e-03, 1.8551974e-02, 9.7193110e-01],\n",
       "       [3.7030253e-04, 9.9285829e-01, 6.7713992e-03],\n",
       "       [1.6079340e-02, 1.7321566e-02, 9.6659911e-01],\n",
       "       [3.8657314e-04, 9.9735332e-01, 2.2601369e-03],\n",
       "       [1.2095975e-03, 9.9602216e-01, 2.7682786e-03],\n",
       "       [9.7170579e-01, 1.9373124e-02, 8.9210542e-03],\n",
       "       [3.3465607e-04, 9.9836272e-01, 1.3025805e-03],\n",
       "       [9.1149890e-01, 7.2986923e-02, 1.5514221e-02]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment1[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3001c32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brad Smith, Microsoft president, says he believes A.I. regulation will happen in the coming year\n",
      "S. Koreas antitrust regulator approves Microsofts takeover of \n",
      "BHP unleashes the power of digital at worlds largest copper \n",
      "Microsoft Work Trend Index 2023: Singapore data unveils\n",
      "Microsoft signs deal for A.I. computing power with Nvidia-backed CoreWeave that could be worth billions\n",
      "Microsoft pens AI cloud computing deal with former Ethereum miner CoreWeave: CNBC\n",
      "Goodbye, Cortana: Microsoft’s lively voice assistant will soon leave Windows\n",
      "Microsoft faces uninsurable GDPR penalty\n",
      "FTC Will Require Microsoft to Pay $20 million over Charges it\n",
      "Microsoft to pay $20 million FTC fine over storage of Xbox information\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentiment1)-10,len(sentiment1)):\n",
    "    print(news_df.iloc[i].headline1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ce6b2",
   "metadata": {},
   "source": [
    "## Comments:\n",
    "\n",
    "Due to limited processing capabilities of the computer, we will run the code on google_colab and save the sentiments in a file. We will use that file as data when training the final model for stock price prediction.\n",
    "\n",
    "Below, we will read the sentiment dataframe created on google colaboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "659e40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_csv('/Users/pushkal/Documents/GitHub/stock_price_prediction/news_data/msft_sentiment_values_colab/sentiment_data_frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56a2e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-1-1</th>\n",
       "      <td>0.184596</td>\n",
       "      <td>0.610093</td>\n",
       "      <td>0.205312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-1-2</th>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.962005</td>\n",
       "      <td>0.026156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-1-3</th>\n",
       "      <td>0.078713</td>\n",
       "      <td>0.418107</td>\n",
       "      <td>0.503180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-1-4</th>\n",
       "      <td>0.021134</td>\n",
       "      <td>0.623070</td>\n",
       "      <td>0.355795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-1-5</th>\n",
       "      <td>0.182176</td>\n",
       "      <td>0.718622</td>\n",
       "      <td>0.099203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-6-2</th>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.791215</td>\n",
       "      <td>0.204954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-6-3</th>\n",
       "      <td>0.143502</td>\n",
       "      <td>0.853986</td>\n",
       "      <td>0.002513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-6-4</th>\n",
       "      <td>0.195494</td>\n",
       "      <td>0.800462</td>\n",
       "      <td>0.004044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-6-5</th>\n",
       "      <td>0.207483</td>\n",
       "      <td>0.772059</td>\n",
       "      <td>0.020458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-6-6</th>\n",
       "      <td>0.186342</td>\n",
       "      <td>0.789545</td>\n",
       "      <td>0.024113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1253 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative   neutral  positive\n",
       "date                                  \n",
       "2020-1-1  0.184596  0.610093  0.205312\n",
       "2020-1-2  0.011839  0.962005  0.026156\n",
       "2020-1-3  0.078713  0.418107  0.503180\n",
       "2020-1-4  0.021134  0.623070  0.355795\n",
       "2020-1-5  0.182176  0.718622  0.099203\n",
       "...            ...       ...       ...\n",
       "2023-6-2  0.003831  0.791215  0.204954\n",
       "2023-6-3  0.143502  0.853986  0.002513\n",
       "2023-6-4  0.195494  0.800462  0.004044\n",
       "2023-6-5  0.207483  0.772059  0.020458\n",
       "2023-6-6  0.186342  0.789545  0.024113\n",
       "\n",
       "[1253 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = sentiment_df.set_index('date')\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce86daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
